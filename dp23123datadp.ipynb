{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a5d7eec1",
   "metadata": {},
   "source": [
    "***GENERATED CODE FOR dp23123datadp PIPELINE.***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7ed469a",
   "metadata": {},
   "source": [
    "***DON'T EDIT THIS CODE.***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8edda170",
   "metadata": {},
   "source": [
    "***CONNECTOR FUNCTIONS TO READ DATA.***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6396ef29",
   "metadata": {},
   "outputs": [],
   "source": [
    "from hdfs3 import HDFileSystem\n",
    "import datetime\n",
    "import logging\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "logging.basicConfig(format='%(levelname)s:%(message)s', level=logging.INFO)\n",
    "\n",
    "\n",
    "class HDFSConnector:\n",
    "\n",
    "    def fetch(spark, config):\n",
    "        ################### INPUT HADOOP HOST PORT TO CONNECT WITH ###############################\n",
    "        hdfs = HDFileSystem(\n",
    "            host=eval(config)['host'], port=eval(config)['port'])\n",
    "        with hdfs.open(eval(config)['url']) as f:\n",
    "            df = pd.read_csv(f, error_bad_lines=False)\n",
    "        df = spark.createDataFrame(dfPd)\n",
    "        display(df.limit(2).toPandas())\n",
    "        return df\n",
    "\n",
    "    def put(df, spark, config):\n",
    "        return df.write.format('csv').options(header='true' if eval(config)[\"is_header\"] == \"Use Header Line\" else 'false',\n",
    "                                              delimiter=eval(config)[\"delimiter\"]).save((\"%s %s\") % (datetime.datetime.now().strftime(\"%Y-%m-%d %H.%M.%S\")+\"_\", eval(config)['url']))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f95b75f",
   "metadata": {},
   "source": [
    "***OPERATION FUNCTIONS***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee1e028e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from dask.dataframe import from_pandas\n",
    "import json\n",
    "\n",
    "\n",
    "def aggregation(df, functionsData, applyOn):\n",
    "    dfcp = df\n",
    "    for functionData in functionsData:\n",
    "        aggregateOn = []\n",
    "        groupOn = []\n",
    "\n",
    "        for column in functionData['aggregateOn']:\n",
    "            aggregateOn.append(column['columnName'])\n",
    "        for column in functionData['groupOn']:\n",
    "            groupOn.append(column['columnName'])\n",
    "        if functionData['aggregateFunction'] == 'count':\n",
    "            dfcp = (df.groupby(groupOn))[aggregateOn].count()\n",
    "        elif functionData['aggregateFunction'] == 'min':\n",
    "            dfcp = (df.groupby(groupOn))[aggregateOn].min()\n",
    "        elif functionData['aggregateFunction'] == 'max':\n",
    "            dfcp = (df.groupby(groupOn))[aggregateOn].max()\n",
    "        elif functionData['aggregateFunction'] == 'std':\n",
    "            dfcp = (df.groupby(groupOn))[aggregateOn].std()\n",
    "        elif functionData['aggregateFunction'] == 'mean':\n",
    "            dfcp = (df.groupby(groupOn))[aggregateOn].mean()\n",
    "        elif functionData['aggregateFunction'] == 'sum':\n",
    "            dfcp = (df.groupby(groupOn))[aggregateOn].sum()\n",
    "    return dfcp\n",
    "\n",
    "\n",
    "def runDataCleansing(sparkDf, spark, config):\n",
    "    configObj = json.loads(config)\n",
    "    sparkDf.persist(pyspark.StorageLevel.MEMORY_AND_DISK)\n",
    "    df = from_pandas((sparkDf.toPandas()), npartitions=5)\n",
    "    functionList = configObj['functionsApplied']\n",
    "    Data_Cleansing_Methods = {\"replaceBy\": replaceValues,\n",
    "                              \"formula\": calculateFormula,\n",
    "                              \"aggregate\": aggregation,\n",
    "                              \"converttostringtype\": changeToString,\n",
    "                              \"editname\": renameColumns}\n",
    "    for function in functionList:\n",
    "        function['functionName']\n",
    "        df = Data_Cleansing_Methods[function['functionName']](df, function['functionsData'],\n",
    "                                                              function['applyOn'])\n",
    "    sparkDf = spark.createDataFrame(df.compute())\n",
    "\n",
    "    display(sparkDf.limit(2).toPandas())\n",
    "    return sparkDf\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fc9dc77",
   "metadata": {},
   "source": [
    "***CONNECTOR FUNCTIONS TO WRITE DATA.***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d85880d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import requests\n",
    "import datetime\n",
    "import logging\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "logging.basicConfig(format='%(levelname)s:%(message)s', level=logging.INFO)\n",
    "\n",
    "\n",
    "class NumtraConnector:\n",
    "\n",
    "    def put(inStages, inStagesData, stageId, spark, config):\n",
    "        path = eval(config)['server_url']\n",
    "        baseType = eval(config)['baseType']\n",
    "        results_url = eval(config)['results_url']\n",
    "        server = eval(config)['server']\n",
    "        originalfile = eval(config)['orignalKey']\n",
    "        eval(config)['pathOnly']\n",
    "        filename = eval(config)['filename']\n",
    "        eval(config)['ser']\n",
    "        eval(config)['user']\n",
    "        eval(config)['password']\n",
    "        eval(config)['authSource']\n",
    "        eval(config)['user_id']\n",
    "        eval(config)['parent_id']\n",
    "        eval(config)['project_id']\n",
    "        time = str(int(datetime.datetime.now().timestamp()))\n",
    "\n",
    "        inStagesData[inStages[0]]\n",
    "\n",
    "        print(path)\n",
    "        print(baseType)\n",
    "        print(results_url)\n",
    "        print(server)\n",
    "        print(originalfile)\n",
    "        print(filename)\n",
    "\n",
    "        args = {\n",
    "            'url': path,\n",
    "            'baseType': baseType,\n",
    "            'originalfile': originalfile,\n",
    "            'filename': time + filename\n",
    "        }\n",
    "\n",
    "        response = requests.post(results_url, args)\n",
    "        return response\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d1d67ff",
   "metadata": {},
   "source": [
    "***READING DATAFRAME***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1710877b",
   "metadata": {},
   "outputs": [],
   "source": [
    "############## CREATE SPARK SESSION ############################ ENTER YOUR SPARK MASTER IP AND PORT TO CONNECT TO SERVER ################from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.master('spark://0.0.0.0:0000').getOrCreate()\n",
    "#%run dp23123datadpHooks.ipynb\n",
    "try:\n",
    "\t#sourcePreExecutionHook()\n",
    "\n",
    "\tdpdataf = HDFSConnector.fetch(spark, \"{'url': '/FileStore/platform/uploadedSourceFiles/part-00000-158fc2b9-01e6-4283-953a-929d34d4458a-c000.csv', 'filename': '1674484305DP23122DataF.csv', 'delimiter': ',', 'file_type': 'Delimeted', 'dbfs_token': '', 'dbfs_domain': '', 'FilePath': '/dataPipeline/DP23122DataF.csv', 'viewFileName': 'DP23122DataF.csv', 'is_header': 'Use Header Line', 'baseType': 'hdfs', 'server_url': '/numtraPlatform/NumtraPlatformV2/uploads/platform/', 'results_url': 'http://dev.numtra.com:4040/api/read/hdfs'}\")\n",
    "\n",
    "except Exception as ex: \n",
    "\tlogging.error(ex)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9006afcb",
   "metadata": {},
   "source": [
    "***PERFORMING OPERATIONS***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feca139b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%run dp23123datadpHooks.ipynb\n",
    "try:\n",
    "\t#operationPreExecutionHook()\n",
    "\n",
    "datapreparation = runDataCleansing(dpdataf,spark,json.dumps( {\"url\": \"/FileStore/platform/uploadedSourceFiles/part-00000-158fc2b9-01e6-4283-953a-929d34d4458a-c000.csv\", \"source_attributes\": {}, \"DataPrepFile\": \"/FileStore/platform/uploadedSourceFiles/part-00000-158fc2b9-01e6-4283-953a-929d34d4458a-c000.csv\", \"data_source\": \"platfiles\", \"startListenerOnly\": 1, \"dateColumnNames\": [\"effective_date\", \"due_date\", \"paid_off_time\"], \"FilePath\": \"/FileStore/platform/extra/63ce9dd9c6466544d4d49c451674485461/0part.csv\", \"requestRatio\": 0.0, \"totalRows\": 6, \"BasicStats\": {\"missingValues\": 833.3, \"numberOfColumns\": 11, \"numberOfRows\": 6, \"duplicateRowCount\": 0, \"stats\": [{\"column\": \"Loan_ID\", \"alias\": \"Loan_ID\", \"generated\": 0, \"type\": \"String\", \"max\": \"xqd20168902\", \"min\": \"xqd20160003\", \"mean\": \"\", \"missing\": 0.0, \"stddev\": \"\", \"outliers\": [], \"validation\": []}, {\"column\": \"loan_status\", \"alias\": \"loan_status\", \"generated\": 0, \"type\": \"String\", \"max\": \"PAIDOFF\", \"min\": \"COLLECTION\", \"mean\": \"\", \"missing\": 0.0, \"stddev\": \"\", \"outliers\": [], \"validation\": []}, {\"column\": \"Principal\", \"alias\": \"Principal\", \"generated\": 0, \"type\": \"numeric\", \"max\": 1000, \"min\": 1000, \"mean\": 1000.0, \"missing\": 0.0, \"stddev\": 0.0, \"outliers\": [], \"validation\": []}, {\"column\": \"terms\", \"alias\": \"terms\", \"generated\": 0, \"type\": \"numeric\", \"max\": 30, \"min\": 15, \"mean\": 25.0, \"missing\": 0.0, \"stddev\": 7.75, \"outliers\": [], \"validation\": []}, {\"column\": \"effective_date\", \"alias\": \"effective_date\", \"generated\": 0, \"type\": \"date\", \"max\": \"201699\", \"min\": \"201698\", \"mean\": \"\", \"missing\": 0.0, \"stddev\": \"\", \"outliers\": [], \"validation\": \"[]\"}, {\"column\": \"due_date\", \"alias\": \"due_date\", \"generated\": 0, \"type\": \"date\", \"max\": \"2016108\", \"min\": \"2016922\", \"mean\": \"\", \"missing\": 0.0, \"stddev\": \"\", \"outliers\": [], \"validation\": \"[]\"}, {\"column\": \"paid_off_time\", \"alias\": \"paid_off_time\", \"generated\": 0, \"type\": \"date\", \"max\": \"2016107\", \"min\": \"2016914\", \"mean\": \"\", \"missing\": 16.7, \"stddev\": \"\", \"outliers\": [], \"validation\": \"[{\\\"1\\\": NaN}]\"}, {\"column\": \"past_due_days\", \"alias\": \"past_due_days\", \"generated\": 0, \"type\": \"real\", \"max\": 75.0, \"min\": 0.0, \"mean\": 48.75, \"missing\": 33.3, \"stddev\": 33.26, \"outliers\": [0.0], \"validation\": []}, {\"column\": \"age\", \"alias\": \"age\", \"generated\": 0, \"type\": \"numeric\", \"max\": 50, \"min\": 27, \"mean\": 35.333333333333336, \"missing\": 0.0, \"stddev\": 9.77, \"outliers\": [], \"validation\": []}, {\"column\": \"education\", \"alias\": \"education\", \"generated\": 0, \"type\": \"String\", \"max\": \"college\", \"min\": \"Bechalor\", \"mean\": \"\", \"missing\": 0.0, \"stddev\": \"\", \"outliers\": [], \"validation\": []}, {\"column\": \"Gender\", \"alias\": \"Gender\", \"generated\": 0, \"type\": \"String\", \"max\": \"male\", \"min\": \"female\", \"mean\": \"\", \"missing\": 0.0, \"stddev\": \"\", \"outliers\": [], \"validation\": []}]}, \"predictionPowerScore\": [{\"Gender\": 1.0, \"Loan_ID\": 0.0, \"Principal\": 0.0, \"age\": 0.0, \"due_date\": 0.0, \"education\": 0.0, \"effective_date\": 0.0, \"loan_status\": 0.0, \"paid_off_time\": 0.0, \"past_due_days\": 0.0, \"terms\": 0.0}, {\"Gender\": 0.0, \"Loan_ID\": 1.0, \"Principal\": 0.0, \"age\": 0.0, \"due_date\": 0.0, \"education\": 0.0, \"effective_date\": 0.0, \"loan_status\": 0.0, \"paid_off_time\": 0.0, \"past_due_days\": 0.0, \"terms\": 0.0}, {\"Gender\": 0.0, \"Loan_ID\": 0.0, \"Principal\": 1.0, \"age\": 0.0, \"due_date\": 0.0, \"education\": 0.0, \"effective_date\": 0.0, \"loan_status\": 0.0, \"paid_off_time\": 0.0, \"past_due_days\": 0.0, \"terms\": 0.0}, {\"Gender\": 0.0, \"Loan_ID\": 0.0, \"Principal\": 0.0, \"age\": 1.0, \"due_date\": 0.0, \"education\": 0.0, \"effective_date\": 0.0, \"loan_status\": 0.0, \"paid_off_time\": 0.0, \"past_due_days\": 0.0, \"terms\": 0.0}, {\"Gender\": 0.0, \"Loan_ID\": 0.0, \"Principal\": 0.0, \"age\": 0.0, \"due_date\": 1.0, \"education\": 0.0, \"effective_date\": 0.0, \"loan_status\": 0.0, \"paid_off_time\": 0.0, \"past_due_days\": 0.0, \"terms\": 0.0}, {\"Gender\": 0.0, \"Loan_ID\": 0.0, \"Principal\": 0.0, \"age\": 0.0, \"due_date\": 0.0, \"education\": 1.0, \"effective_date\": 0.0, \"loan_status\": 0.0, \"paid_off_time\": 0.0, \"past_due_days\": 0.0, \"terms\": 0.0}, {\"Gender\": 0.0, \"Loan_ID\": 0.0, \"Principal\": 0.0, \"age\": 0.0, \"due_date\": 0.0, \"education\": 0.0, \"effective_date\": 1.0, \"loan_status\": 0.0, \"paid_off_time\": 0.0, \"past_due_days\": 0.0, \"terms\": 0.0}, {\"Gender\": 0.0, \"Loan_ID\": 0.0, \"Principal\": 0.3125, \"age\": 0.3125, \"due_date\": 0.0, \"education\": 0.0, \"effective_date\": 0.0, \"loan_status\": 1.0, \"paid_off_time\": 0.0, \"past_due_days\": 0.0, \"terms\": 0.0}, {\"Gender\": 0.0, \"Loan_ID\": 0.0, \"Principal\": 0.0, \"age\": 0.0, \"due_date\": 0.0, \"education\": 0.0, \"effective_date\": 0.0, \"loan_status\": 0.0, \"paid_off_time\": 1.0, \"past_due_days\": 0.0, \"terms\": 0.0}, {\"Gender\": 0.0, \"Loan_ID\": 0.0, \"Principal\": 0.0, \"age\": 0.0, \"due_date\": 0.0, \"education\": 0.0, \"effective_date\": 0.0, \"loan_status\": 0.0, \"paid_off_time\": 0.0, \"past_due_days\": 1.0, \"terms\": 0.0}, {\"Gender\": 0.4375, \"Loan_ID\": 0.0, \"Principal\": 0.0, \"age\": 0.0, \"due_date\": 1.0, \"education\": 0.0, \"effective_date\": 0.0, \"loan_status\": 0.0, \"paid_off_time\": 0.0, \"past_due_days\": 0.0, \"terms\": 1.0}], \"HasBasicStats\": 1, \"functionsApplied\": [{\"functionName\": \"aggregate\", \"applyOn\": [{\"columnName\": \"effective_date\", \"type\": \"date\", \"min\": \"201698\", \"max\": \"201699\", \"mean\": \"-\"}], \"functionsData\": [{\"aggregateFunction\": \"\", \"aggregateOn\": [{\"columnName\": \"effective_date\", \"type\": \"date\", \"min\": \"201698\", \"max\": \"201699\", \"mean\": \"-\"}], \"groupOn\": [{\"columnName\": \"Gender\", \"type\": \"String\", \"min\": \"female\", \"max\": \"male\", \"mean\": \"-\"}]}]}], \"functionChanges\": [{\"columnName\": \"effective_date\", \"functionName\": \"Aggregate\", \"Type\": \"date\", \"Parameters\": [{\"aggregateFunction\": \"\", \"aggregateOn\": [{\"columnName\": \"effective_date\", \"type\": \"date\", \"min\": \"201698\", \"max\": \"201699\", \"mean\": \"-\"}], \"groupOn\": [{\"columnName\": \"Gender\", \"type\": \"String\", \"min\": \"female\", \"max\": \"male\", \"mean\": \"-\"}]}]}], \"fileheader\": [{\"field\": \"Loan_ID\", \"alias\": \"Loan_ID\", \"generated\": 0, \"position\": 1, \"type\": \"String\"}, {\"field\": \"loan_status\", \"alias\": \"loan_status\", \"generated\": 0, \"position\": 2, \"type\": \"String\"}, {\"field\": \"Principal\", \"alias\": \"Principal\", \"generated\": 0, \"position\": 3, \"type\": \"numeric\"}, {\"field\": \"terms\", \"alias\": \"terms\", \"generated\": 0, \"position\": 4, \"type\": \"numeric\"}, {\"field\": \"effective_date\", \"alias\": \"effective_date\", \"generated\": 0, \"position\": 5, \"type\": \"date\"}, {\"field\": \"due_date\", \"alias\": \"due_date\", \"generated\": 0, \"position\": 6, \"type\": \"date\"}, {\"field\": \"paid_off_time\", \"alias\": \"paid_off_time\", \"generated\": 0, \"position\": 7, \"type\": \"date\"}, {\"field\": \"past_due_days\", \"alias\": \"past_due_days\", \"generated\": 0, \"position\": 8, \"type\": \"real\"}, {\"field\": \"age\", \"alias\": \"age\", \"generated\": 0, \"position\": 9, \"type\": \"numeric\"}, {\"field\": \"education\", \"alias\": \"education\", \"generated\": 0, \"position\": 10, \"type\": \"String\"}, {\"field\": \"Gender\", \"alias\": \"Gender\", \"generated\": 0, \"position\": 11, \"type\": \"String\"}]}))\n",
    "\t#operationPostExecutionHook(datapreparation)\n",
    "\n",
    "except Exception as ex: \n",
    "\tlogging.error(ex)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e55fe8cc",
   "metadata": {},
   "source": [
    "***WRITING DATAFRAME***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb27602a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%run dp23123datadpHooks.ipynb\n",
    "try:\n",
    "\t#sinkPreExecutionHook()\n",
    "\n",
    "\tdatapipeline = NumtraConnector.fetch(spark, \"{'samplefile': '/FileStore/platform/sampleData/63ce9dd6c6466544d4d49c41/part-00000-2434a021-bb2d-46a8-8a9e-d317bff3dbcf-c000.csv', 'samplecount': 6, 'originalcount': 6, 'orignalKey': '/FileStore/platform/uploadedSourceFiles/part-00000-158fc2b9-01e6-4283-953a-929d34d4458a-c000.csv', 'pathOnly': '/dataPipeline', 'project_id': '63c0fe048b96720de22fd1f9', 'parent_id': '63c0fe048b96720de22fd1f9', 'original_schema': [{'checked': True, 'inherited': True, 'is_categorical': False, 'bad_values': '', 'nullable': 'true', 'field': 'Loan_ID', 'alias': 'Loan_ID', 'type': 'String', 'position': '0'}, {'checked': True, 'inherited': True, 'is_categorical': False, 'bad_values': '', 'nullable': 'true', 'field': 'loan_status', 'alias': 'loan_status', 'type': 'String', 'position': '1'}, {'checked': True, 'inherited': True, 'is_categorical': False, 'bad_values': '', 'nullable': 'true', 'field': 'Principal', 'alias': 'Principal', 'type': 'numeric', 'position': '2'}, {'checked': True, 'inherited': True, 'is_categorical': False, 'bad_values': '', 'nullable': 'true', 'field': 'terms', 'alias': 'terms', 'type': 'numeric', 'position': '3'}, {'checked': True, 'inherited': True, 'is_categorical': False, 'bad_values': '', 'nullable': 'true', 'field': 'effective_date', 'alias': 'effective_date', 'type': 'date', 'position': '4'}, {'checked': True, 'inherited': True, 'is_categorical': False, 'bad_values': '', 'nullable': 'true', 'field': 'due_date', 'alias': 'due_date', 'type': 'date', 'position': '5'}, {'checked': True, 'inherited': True, 'is_categorical': False, 'bad_values': '', 'nullable': 'true', 'field': 'paid_off_time', 'alias': 'paid_off_time', 'type': 'date', 'position': '6'}, {'checked': True, 'inherited': True, 'is_categorical': False, 'bad_values': '', 'nullable': 'true', 'field': 'past_due_days', 'alias': 'past_due_days', 'type': 'real', 'position': '7'}, {'checked': True, 'inherited': True, 'is_categorical': False, 'bad_values': '', 'nullable': 'true', 'field': 'age', 'alias': 'age', 'type': 'numeric', 'position': '8'}, {'checked': True, 'inherited': True, 'is_categorical': False, 'bad_values': '', 'nullable': 'true', 'field': 'education', 'alias': 'education', 'type': 'String', 'position': '9'}, {'checked': True, 'inherited': True, 'is_categorical': False, 'bad_values': '', 'nullable': 'true', 'field': 'Gender', 'alias': 'Gender', 'type': 'String', 'position': '10'}], 'actual_schema': [{'checked': True, 'inherited': True, 'is_categorical': False, 'bad_values': '', 'nullable': 'true', 'field': 'Loan_ID', 'alias': 'Loan_ID', 'type': 'String', 'position': '0'}, {'checked': True, 'inherited': True, 'is_categorical': False, 'bad_values': '', 'nullable': 'true', 'field': 'loan_status', 'alias': 'loan_status', 'type': 'String', 'position': '1'}, {'checked': True, 'inherited': True, 'is_categorical': False, 'bad_values': '', 'nullable': 'true', 'field': 'Principal', 'alias': 'Principal', 'type': 'numeric', 'position': '2'}, {'checked': True, 'inherited': True, 'is_categorical': False, 'bad_values': '', 'nullable': 'true', 'field': 'terms', 'alias': 'terms', 'type': 'numeric', 'position': '3'}, {'checked': True, 'inherited': True, 'is_categorical': False, 'bad_values': '', 'nullable': 'true', 'field': 'effective_date', 'alias': 'effective_date', 'type': 'numeric', 'position': '4'}, {'checked': True, 'inherited': True, 'is_categorical': False, 'bad_values': '', 'nullable': 'true', 'field': 'due_date', 'alias': 'due_date', 'type': 'numeric', 'position': '5'}, {'checked': True, 'inherited': True, 'is_categorical': False, 'bad_values': '', 'nullable': 'true', 'field': 'paid_off_time', 'alias': 'paid_off_time', 'type': 'real', 'position': '6'}, {'checked': True, 'inherited': True, 'is_categorical': False, 'bad_values': '', 'nullable': 'true', 'field': 'past_due_days', 'alias': 'past_due_days', 'type': 'real', 'position': '7'}, {'checked': True, 'inherited': True, 'is_categorical': False, 'bad_values': '', 'nullable': 'true', 'field': 'age', 'alias': 'age', 'type': 'numeric', 'position': '8'}, {'checked': True, 'inherited': True, 'is_categorical': False, 'bad_values': '', 'nullable': 'true', 'field': 'education', 'alias': 'education', 'type': 'String', 'position': '9'}, {'checked': True, 'inherited': True, 'is_categorical': False, 'bad_values': '', 'nullable': 'true', 'field': 'Gender', 'alias': 'Gender', 'type': 'String', 'position': '10'}], 'server': 'https://dev.numtra.com:443', 'server_url': '/numtraPlatform/NumtraPlatformV2/uploads/platform/', 'delimiter': ',', 'file_type': 'Delimeted', 'filename': 'DP23123DPData.csv', 'token': '', 'domain': '', 'is_header': 'Use Header Line', 'url': '/FileStore/platform/uploadedSourceFiles/part-00000-0aa4effc-84b4-4652-b919-987f8cf94325-c000.csv', 'results_url': 'http://dev.numtra.com:4040/api/read/hdfs'}\")\n",
    "\n",
    "except Exception as ex: \n",
    "\tlogging.error(ex)\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
